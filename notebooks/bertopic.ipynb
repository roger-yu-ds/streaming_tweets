{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a237f8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook trains an NLP model with PySpark and Spark NLP from scratch. \n",
    "* The data set contains 18,030 tweets in parquet format; `data/raw/twitter_flat.parquet`.\n",
    "* The trained model is saved in the `models` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddcdaee",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f55da26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing optional module skimage\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/_plotly_utils/optional_imports.py\", line 30, in get_module\n",
      "    return import_module(name)\n",
      "  File \"/opt/conda/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/skimage/__init__.py\", line 135, in <module>\n",
      "    from .data import data_dir\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/skimage/data/__init__.py\", line 270, in <module>\n",
      "    _init_pooch()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/skimage/data/__init__.py\", line 256, in _init_pooch\n",
      "    shutil.copy2(osp.join(skimage_distribution_dir, 'data', 'README.txt'),\n",
      "  File \"/opt/conda/lib/python3.8/shutil.py\", line 436, in copy2\n",
      "    copystat(src, dst, follow_symlinks=follow_symlinks)\n",
      "  File \"/opt/conda/lib/python3.8/shutil.py\", line 375, in copystat\n",
      "    lookup(\"utime\")(dst, ns=(st.st_atime_ns, st.st_mtime_ns),\n",
      "PermissionError: [Errno 1] Operation not permitted\n"
     ]
    }
   ],
   "source": [
    "from datetime import (\n",
    "    datetime,\n",
    "    timedelta\n",
    ")\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from bertopic import BERTopic\n",
    "from joblib import (\n",
    "    dump,\n",
    "    load\n",
    ")\n",
    "\n",
    "from pyspark.sql import (\n",
    "    SparkSession,\n",
    "    functions as F\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    StringType,\n",
    "    StructType,\n",
    "    StructField,\n",
    "    IntegerType,\n",
    "    LongType,\n",
    "    BooleanType,\n",
    "    MapType\n",
    ")\n",
    "import sparknlp\n",
    "from sparknlp import Finisher\n",
    "from pyspark.ml import (\n",
    "    Pipeline\n",
    ")\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "from wordcloud import (\n",
    "    WordCloud, \n",
    "    STOPWORDS, \n",
    "    ImageColorGenerator\n",
    ")\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237eee6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.version: 3.1.1\n",
      "sparknlp.version(): 3.1.0\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "print(f'spark.version: {spark.version}')\n",
    "print(f'sparknlp.version(): {sparknlp.version()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aaef42",
   "metadata": {},
   "source": [
    "# Set up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c628b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_dir = Path.cwd().parent\n",
    "models_dir = project_dir / 'models'\n",
    "pretrained_models_dir = models_dir / 'pretrained'\n",
    "data_dir = project_dir / 'data'\n",
    "raw_data_dir = data_dir / 'raw'\n",
    "processed_data_dir = data_dir / 'processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e28fc4",
   "metadata": {},
   "source": [
    "# Load parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5c652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = raw_data_dir / 'twitter_flat.parquet'\n",
    "# `spark.read.parquet` can't infer schema for some reason\n",
    "# so load into pandas df first\n",
    "pdf = pd.read_parquet(path)\n",
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60281d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1778f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_longer(text1, text2):\n",
    "    result = text1\n",
    "    if text2 is not None:\n",
    "        result = text2    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39087d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Get the full text and assign to the `text` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975f76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf.loc[:, 'text'] = pdf.apply(lambda s: get_longer(s.text, s.extended_full_text), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1e483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = pdf.text.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73c6ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12b1cb95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = models_dir / 'topic_model'\n",
    "if path.with_suffix('.joblib').exists():\n",
    "    topic_model = load(path.with_suffix('.joblib'))\n",
    "else:\n",
    "    # Training takes ~15 minutes\n",
    "    topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "    topics, probs = topic_model.fit_transform(docs)\n",
    "    dump(topic_model, path.with_suffix('.joblib'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f445156",
   "metadata": {
    "tags": []
   },
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "freq.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9eb4095",
   "metadata": {
    "tags": []
   },
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73ee273b",
   "metadata": {
    "tags": []
   },
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6acae7",
   "metadata": {},
   "source": [
    "# Transform one topic"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b21347bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T05:21:37.961653Z",
     "iopub.status.busy": "2021-06-12T05:21:37.961268Z",
     "iopub.status.idle": "2021-06-12T05:21:37.968058Z",
     "shell.execute_reply": "2021-06-12T05:21:37.966447Z",
     "shell.execute_reply.started": "2021-06-12T05:21:37.961620Z"
    },
    "tags": []
   },
   "source": [
    "def get_topic_name(prediction, topic_model):\n",
    "    \"\"\"\n",
    "    Convenience functions to get the name of the \n",
    "    topic with the highest probability.\n",
    "    \"\"\"\n",
    "    return topic_model.get_topics()[prediction[0][0]][0][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03657641",
   "metadata": {
    "tags": []
   },
   "source": [
    "test_prediction = topic_model.transform('I like bitcoin!')\n",
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0cad026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_name(test_prediction, topic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c498c",
   "metadata": {},
   "source": [
    "# Stream topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0612f834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stream_df = (\n",
    "    spark \n",
    "    .readStream \n",
    "    .format(\"kafka\") \n",
    "    .option(\"kafka.bootstrap.servers\", \"broker:29092\") \n",
    "    .option(\"startingOffsets\", \"earliest\") \n",
    "    .option(\"subscribe\", \"twitterdata\") \n",
    "#     .option(\"maxOffsetsPerTrigger\",1)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c998a680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_schema = StructType([\n",
    "    StructField('created_at', StringType(), True),\n",
    "    StructField('id', LongType(), True),\n",
    "    StructField('text', StringType(), True),\n",
    "    StructField('is_quote_status', BooleanType(), True),\n",
    "    StructField('in_reply_to_user_id', LongType(), True),\n",
    "    StructField('user', StructType([\n",
    "        StructField('id', LongType(), True),\n",
    "        StructField('followers_count', IntegerType(), True),\n",
    "        StructField('friends_count', IntegerType(), True),\n",
    "        StructField('created_at', StringType(), True)\n",
    "    ])),\n",
    "    StructField('extended_tweet', StructType([\n",
    "        StructField('full_text', StringType(), True)\n",
    "    ])),\n",
    "    StructField('retweeted_status', StructType([\n",
    "        StructField('id', LongType(), True)\n",
    "    ])),\n",
    "    StructField('retweet_count', IntegerType(), True),\n",
    "    StructField('favorite_count', IntegerType(), True),\n",
    "    StructField('quote_count', IntegerType(), True),\n",
    "    StructField('reply_count', IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7260f3e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T06:53:11.314555Z",
     "iopub.status.busy": "2021-06-12T06:53:11.314232Z",
     "iopub.status.idle": "2021-06-12T06:53:11.453217Z",
     "shell.execute_reply": "2021-06-12T06:53:11.451754Z",
     "shell.execute_reply.started": "2021-06-12T06:53:11.314514Z"
    },
    "tags": []
   },
   "source": [
    "# The predicate doesn't work for some reason, the data frame keeps growing.\n",
    "predicate = 'timestamp > (CURRENT_TIMESTAMP() - INTERVAL 1 seconds)'\n",
    "tweet_stream_df = (\n",
    "    stream_df\n",
    "    # Convert the key and value from binary to StringType\n",
    "    .withColumn('key', stream_df['key'].cast(StringType()))\n",
    "    .withColumn('value', stream_df['value'].cast(StringType()))\n",
    "    # Assign fields to JSON\n",
    "    .withColumn('value', F.from_json('value', tweet_schema))\n",
    "    .select('timestamp',\n",
    "            'value.created_at',\n",
    "            'value.text',\n",
    "            'value.extended_tweet.full_text')\n",
    "    .where(predicate)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6eb3ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_stream_df = (\n",
    "    stream_df\n",
    "    # Convert the key and value from binary to StringType\n",
    "    .withColumn('key', stream_df['key'].cast(StringType()))\n",
    "    .withColumn('value', stream_df['value'].cast(StringType()))\n",
    "    # Assign fields to JSON\n",
    "    .withColumn('value', F.from_json('value', tweet_schema))\n",
    "    .select('timestamp',\n",
    "            'value.created_at',\n",
    "            'value.text',\n",
    "            'value.extended_tweet.full_text')\n",
    "    .where(stream_df.timestamp > F.current_timestamp() - F.expr('INTERVAL 1 seconds'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de08a37d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- full_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_stream_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba73c2e",
   "metadata": {},
   "source": [
    "## Check `tweet_stream_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd23a6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_stream = (\n",
    "    tweet_stream_df\n",
    "    .writeStream\n",
    "    .format('memory')\n",
    "    .queryName('tweet_view')\n",
    "    .outputMode('update')\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e86f9e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T07:03:12.611413Z",
     "iopub.status.busy": "2021-06-12T07:03:12.610966Z",
     "iopub.status.idle": "2021-06-12T07:03:12.651837Z",
     "shell.execute_reply": "2021-06-12T07:03:12.650233Z",
     "shell.execute_reply.started": "2021-06-12T07:03:12.611340Z"
    },
    "tags": []
   },
   "source": [
    "tweet_stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad261b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           timestamp|                text|\n",
      "+--------------------+--------------------+\n",
      "|2021-06-13 06:52:...|RT @jack: The peo...|\n",
      "|2021-06-13 06:52:...|RT @ladyincrypto:...|\n",
      "|2021-06-13 06:52:...|RT @DaCryptoMonke...|\n",
      "|2021-06-13 06:52:...|12 Ways That I Pa...|\n",
      "|2021-06-13 06:52:...|@GMaurya1411019 @...|\n",
      "|2021-06-13 06:52:...|Treasury Secretar...|\n",
      "|2021-06-13 06:52:...|RT @BVYCrypto: @C...|\n",
      "|2021-06-13 06:52:...|I am starting to ...|\n",
      "|2021-06-13 06:52:...|Possible Uptrend ...|\n",
      "|2021-06-13 06:52:...|How to add the Sm...|\n",
      "|2021-06-13 06:52:...|        Nice project|\n",
      "|2021-06-13 06:52:...|RT @exoswrld: rem...|\n",
      "|2021-06-13 06:52:...|RT @trader1sz: I’...|\n",
      "|2021-06-13 06:52:...|good project\n",
      " #BS...|\n",
      "|2021-06-13 06:52:...|RT @Roobet: $2,50...|\n",
      "|2021-06-13 06:52:...|@JRNYcrypto Imagi...|\n",
      "|2021-06-13 06:52:...|RT @Lion_King_Tok...|\n",
      "|2021-06-13 06:52:...|RT @BitspawnGG: B...|\n",
      "|2021-06-13 06:52:...|Thank you so much...|\n",
      "|2021-06-13 06:52:...|RT @rawfuckclub: ...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_name = 'tweet_view'\n",
    "query = f\"\"\"\n",
    "SELECT timestamp, text\n",
    "FROM {table_name}\n",
    "--WHERE timestamp > (CURRENT_TIMESTAMP() - INTERVAL 1 seconds)\n",
    "\"\"\"\n",
    "query_df = spark.sql(query)\n",
    "query_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d11f6874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb568f",
   "metadata": {},
   "source": [
    "# Create UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf86848e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@F.udf\n",
    "def predict_topic(text):\n",
    "    prediction = topic_model.transform(text)\n",
    "    topic_name = topic_model.get_topics()[prediction[0][0]][0][0]\n",
    "    return topic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53ceb489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.predict_topic(text)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register('predict_topic', predict_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c47288",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           timestamp|                text|\n",
      "+--------------------+--------------------+\n",
      "|2021-06-13 06:52:...|RT @SwapQi: 💥Lau...|\n",
      "|2021-06-13 06:52:...|RT @BaubleNft: Wi...|\n",
      "|2021-06-13 06:52:...|RT @orderally: 🎉...|\n",
      "|2021-06-13 06:52:...|RT @potatoe421770...|\n",
      "|2021-06-13 06:52:...|RT @AlkayalWajdi:...|\n",
      "|2021-06-13 06:52:...|@SwapQi\n",
      "Qiswap is...|\n",
      "|2021-06-13 06:52:...|@bellathorne @the...|\n",
      "|2021-06-13 06:52:...|RT @VincePrince24...|\n",
      "|2021-06-13 06:52:...|RT @bobbyong: Cry...|\n",
      "|2021-06-13 06:52:...|RT @raypaxful: Th...|\n",
      "|2021-06-13 06:52:...|RT @CNBC: Bitcoin...|\n",
      "|2021-06-13 06:52:...|RT @realjunsoncha...|\n",
      "|2021-06-13 06:52:...|@mantarayswap \n",
      "Go...|\n",
      "|2021-06-13 06:52:...|RT @CamelGlobal: ...|\n",
      "|2021-06-13 06:52:...|RT @CryptoTamil: ...|\n",
      "|2021-06-13 06:52:...|@elonmusk #ElonMu...|\n",
      "|2021-06-13 06:52:...|@ArtZentsik Mrs. ...|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "table_name = 'tweet_view'\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "  timestamp\n",
    ", text\n",
    "FROM {table_name}\n",
    "WHERE timestamp > (CURRENT_TIMESTAMP() - INTERVAL 1 seconds)\n",
    "\"\"\"\n",
    "query_df = spark.sql(query)\n",
    "query_df.show()\n",
    "print(query_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26d46b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c6f098709217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted_topic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query_df.select('timestamp', 'text', predict_topic('text').alias('predicted_topic')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c7765bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T06:03:07.818307Z",
     "iopub.status.busy": "2021-06-12T06:03:07.818024Z",
     "iopub.status.idle": "2021-06-12T06:07:07.668303Z",
     "shell.execute_reply": "2021-06-12T06:07:07.664750Z",
     "shell.execute_reply.started": "2021-06-12T06:03:07.818282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|           timestamp|                text|   predicted_topic|\n",
      "+--------------------+--------------------+------------------+\n",
      "|2021-06-12 06:03:...|RT @m1sterone: Th...|               why|\n",
      "|2021-06-12 06:03:...|@TheDoggyCoin shi...|               why|\n",
      "|2021-06-12 06:03:...|RT @evan_van_ness...|               why|\n",
      "|2021-06-12 06:03:...|RT @shiba_coin: H...|    soltanmojtaba6|\n",
      "|2021-06-12 06:03:...|@dens_club @Polyt...|               why|\n",
      "|2021-06-12 06:03:...|@VivetVeritate Wh...|          birthday|\n",
      "|2021-06-12 06:03:...|RT @cycloneprotoc...|       coinwindcom|\n",
      "|2021-06-12 06:03:...|Bitcoin and El Sa...|               why|\n",
      "|2021-06-12 06:03:...|Filecoin and Chia...|             china|\n",
      "|2021-06-12 06:03:...|RT @mythica_magic...|httpstcolbca2w1v4a|\n",
      "|2021-06-12 06:03:...|RT @sama_kasa: Dn...|               sun|\n",
      "|2021-06-12 06:03:...|RT @SPACEdotcom: ...|              halo|\n",
      "|2021-06-12 06:03:...|The price of #Sol...|               why|\n",
      "|2021-06-12 06:03:...|RT @LaikaToken: N...|           pancake|\n",
      "|2021-06-12 06:03:...|@97soob OMG i wan...|          birthday|\n",
      "+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_name = 'tweet_view'\n",
    "query_predict = f\"\"\"\n",
    "SELECT \n",
    "  timestamp\n",
    ", text\n",
    ", predict_topic(text) AS predicted_topic\n",
    "FROM {table_name}\n",
    "WHERE timestamp > (CURRENT_TIMESTAMP() - INTERVAL 1 seconds)\n",
    "\"\"\"\n",
    "query_predict_df = spark.sql(query_predict)\n",
    "query_predict_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.select('timestamp', 'text', predict_topic('text').alias('predicted_topic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478ea01",
   "metadata": {},
   "source": [
    "# Stream to memory\n",
    "\n",
    "Test if the prediction model can stream successfully."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ea7e88f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T07:08:14.915884Z",
     "iopub.status.busy": "2021-06-12T07:08:14.915544Z",
     "iopub.status.idle": "2021-06-12T07:08:15.078809Z",
     "shell.execute_reply": "2021-06-12T07:08:15.076576Z",
     "shell.execute_reply.started": "2021-06-12T07:08:14.915845Z"
    },
    "tags": []
   },
   "source": [
    "predict_stream = (\n",
    "    tweet_stream_df\n",
    "    .select('timestamp', 'text', predict_topic('text').alias('predicted_topic'))\n",
    "    .where(tweet_stream_df.timestamp > (F.current_timestamp() - F.expr('INTERVAL 1 seconds')))\n",
    "    .writeStream\n",
    "    .format('memory')\n",
    "    .queryName('predict_view')\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e0874c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T07:20:29.680307Z",
     "iopub.status.busy": "2021-06-12T07:20:29.679816Z",
     "iopub.status.idle": "2021-06-12T07:20:29.703838Z",
     "shell.execute_reply": "2021-06-12T07:20:29.702359Z",
     "shell.execute_reply.started": "2021-06-12T07:20:29.680249Z"
    },
    "tags": []
   },
   "source": [
    "predict_stream.stop()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f69fd11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T07:08:31.359515Z",
     "iopub.status.busy": "2021-06-12T07:08:31.358594Z",
     "iopub.status.idle": "2021-06-12T07:20:27.669919Z",
     "shell.execute_reply": "2021-06-12T07:20:27.667463Z",
     "shell.execute_reply.started": "2021-06-12T07:08:31.359444Z"
    },
    "tags": []
   },
   "source": [
    "table_name = 'predict_view'\n",
    "query_predicted = f\"\"\"\n",
    "SELECT \n",
    "  timestamp\n",
    ", text\n",
    ", predicted_topic\n",
    "FROM {table_name}\n",
    "-- WHERE timestamp > (CURRENT_TIMESTAMP() - INTERVAL 1 seconds)\n",
    "\"\"\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    query_predict_df = spark.sql(query_predicted)\n",
    "    query_predict_df.show()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e598f36",
   "metadata": {},
   "source": [
    "# Stream to Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f87e3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_checkpoint = processed_data_dir / 'kafka_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a186a2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_stream = (\n",
    "    tweet_stream_df\n",
    "    .select(F.col('text').alias('key'), predict_topic('text').alias('value'))\n",
    "    .where(tweet_stream_df.timestamp > (F.current_timestamp() - F.expr('INTERVAL 1 seconds')))\n",
    "    .writeStream\n",
    "    .format('kafka')\n",
    "    .option('checkpointLocation', kafka_checkpoint.as_posix())\n",
    "    .option(\"kafka.bootstrap.servers\", \"broker:29092\")\n",
    "    .option(\"topic\", \"topic_predictions\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7e8de86d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T09:45:33.039406Z",
     "iopub.status.busy": "2021-06-12T09:45:33.038959Z",
     "iopub.status.idle": "2021-06-12T09:45:33.068131Z",
     "shell.execute_reply": "2021-06-12T09:45:33.064800Z",
     "shell.execute_reply.started": "2021-06-12T09:45:33.039363Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48200987",
   "metadata": {},
   "source": [
    "# Test `topic_predictions` \n",
    "\n",
    "Check if the stream from Kafka is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f319a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df = (\n",
    "    spark \n",
    "    .readStream \n",
    "    .format(\"kafka\") \n",
    "    .option(\"kafka.bootstrap.servers\", \"broker:29092\") \n",
    "    .option(\"startingOffsets\", \"earliest\") \n",
    "    .option(\"subscribe\", \"topic_predictions\") \n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85ae3f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7921d861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_raw_stream = (\n",
    "    pred_df\n",
    "    .withColumn('key', pred_df['key'].cast(StringType()))\n",
    "    .withColumn('value', pred_df['value'].cast(StringType()))\n",
    "    .writeStream\n",
    "    .format('memory')\n",
    "    .queryName('prediction_raw_view')\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a817a820",
   "metadata": {
    "tags": []
   },
   "source": [
    "pred_raw_stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8d26bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT *\n",
      "FROM prediction_raw_view\n",
      "\n",
      "+--------------------+------------------+-----------------+---------+------+--------------------+-------------+\n",
      "|                 key|             value|            topic|partition|offset|           timestamp|timestampType|\n",
      "+--------------------+------------------+-----------------+---------+------+--------------------+-------------+\n",
      "|RT @Bad_J0ker: We...|               why|topic_predictions|        0|     0|2021-06-13 06:56:...|            0|\n",
      "|reputation and st...|            richie|topic_predictions|        0|     1|2021-06-13 06:56:...|            0|\n",
      "|Very innovative c...|               why|topic_predictions|        0|     2|2021-06-13 06:56:...|            0|\n",
      "|Burn it all! Init...|               why|topic_predictions|        0|     3|2021-06-13 06:56:...|            0|\n",
      "|How hard is it to...|               why|topic_predictions|        0|     4|2021-06-13 06:56:...|            0|\n",
      "|$XRP $DOGE $CRV H...|               why|topic_predictions|        0|     5|2021-06-13 06:56:...|            0|\n",
      "|with the opportun...|            solana|topic_predictions|        0|     6|2021-06-13 06:56:...|            0|\n",
      "|RT @SafeTheHumani...|          campaign|topic_predictions|        0|     7|2021-06-13 06:56:...|            0|\n",
      "|Nice project.\n",
      "@Br...|        toputoufik|topic_predictions|        0|     8|2021-06-13 06:56:...|            0|\n",
      "|South Africa Work...|              fiat|topic_predictions|        0|     9|2021-06-13 06:56:...|            0|\n",
      "|RT @ID0N0I: I’ll ...|httpstco4cysopir5o|topic_predictions|        0|    10|2021-06-13 06:56:...|            0|\n",
      "|RT @GimmicksPaul:...|            casino|topic_predictions|        0|    11|2021-06-13 06:56:...|            0|\n",
      "|RT @CryptoTownEU:...|               005|topic_predictions|        0|    12|2021-06-13 06:56:...|            0|\n",
      "|@VIRTUAL93023838 ...|          moonshot|topic_predictions|        0|    13|2021-06-13 06:56:...|            0|\n",
      "|RT @dril: my frie...|               why|topic_predictions|        0|    14|2021-06-13 06:56:...|            0|\n",
      "|RT @AliGarb1709: ...|               why|topic_predictions|        0|    15|2021-06-13 06:56:...|            0|\n",
      "|@elonmusk #fiesta...|         candlebsc|topic_predictions|        0|    16|2021-06-13 06:56:...|            0|\n",
      "|RT @Nathan_Combs_...|               why|topic_predictions|        0|    17|2021-06-13 06:56:...|            0|\n",
      "+--------------------+------------------+-----------------+---------+------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_name = 'prediction_raw_view'\n",
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM {table_name}\n",
    "\"\"\"\n",
    "print(query)\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11a80d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT *\n",
      "FROM prediction_raw_view\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(query)\n",
    "spark.sql(query).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e7294",
   "metadata": {},
   "source": [
    "# Stream to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "267703e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T10:07:40.172093Z",
     "iopub.status.busy": "2021-06-12T10:07:40.171599Z",
     "iopub.status.idle": "2021-06-12T10:07:40.178495Z",
     "shell.execute_reply": "2021-06-12T10:07:40.176893Z",
     "shell.execute_reply.started": "2021-06-12T10:07:40.172038Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parquet_path = processed_data_dir / 'prediction_parquet'\n",
    "parquet_checkpoint_path = processed_data_dir / 'prediction_parquet_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "fa0eb599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T10:07:48.547356Z",
     "iopub.status.busy": "2021-06-12T10:07:48.546896Z",
     "iopub.status.idle": "2021-06-12T10:07:48.765177Z",
     "shell.execute_reply": "2021-06-12T10:07:48.763604Z",
     "shell.execute_reply.started": "2021-06-12T10:07:48.547288Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parquet_stream = (\n",
    "    tweet_stream_df\n",
    "    .select(F.col('text').alias('key'), predict_topic('text').alias('value'))\n",
    "    .where(tweet_stream_df.timestamp > (F.current_timestamp() - F.expr('INTERVAL 1 seconds')))\n",
    "    .writeStream\n",
    "    .option('path', parquet_path.as_posix())\n",
    "    .outputMode('append')\n",
    "    .option('checkpointLocation', parquet_checkpoint_path.as_posix())\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "91a709da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-12T10:20:24.709295Z",
     "iopub.status.busy": "2021-06-12T10:20:24.708726Z",
     "iopub.status.idle": "2021-06-12T10:20:28.714229Z",
     "shell.execute_reply": "2021-06-12T10:20:28.713154Z",
     "shell.execute_reply.started": "2021-06-12T10:20:24.709242Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parquet_stream.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
